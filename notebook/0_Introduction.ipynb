{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global overview\n",
    "This project is only for educational purposes. I did it while I was following the `Udacity DataScience nanodegree`.  \n",
    "Within the course, in order to develop our communication skills as DataScientist, we are asked to pick a dataset available on the Internet. There are suggestions but we can take any dataset as soon as we explore it and follow the CRISP-DM process:\n",
    "![CRIP-DM process](../assets/CRISP-DM.png)\n",
    "\n",
    "There are 2 main objectives to reach in this project:\n",
    "* create a Github code repository to share code, scripts, notebooks and documentation about data wrangling/modeling techniques, with a technical audience in mind\n",
    "* write a blog post accessible to non-technical people in order to share our questions, insights, findings, thoughts and conclusions.\n",
    "\n",
    "I chose to use datasets from airbnb and, as a french people, I chose Paris as the city to analyze.\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. `Data Understanding`: [here](1_Data_Understanding.ipynb)\n",
    "2. `Business Understanding`: [here](2_Business_Understanding.ipynb)\n",
    "3. `Data Preparation`: [here](3_Data_Preparation.ipynb)\n",
    "4. `Modeling` and `Evaluation`: [here](4_Modeling.ipynb)\n",
    "5. Tuning models and Evaluation [here](4b_Modeling_Tuning_xgboost.ipynb)\n",
    "\n",
    "The `Deployment` (or `Exposition`) is done through this [blog post](https://nidragedd.github.io/things-you-should-now-before-visiting-Paris/).\n",
    "\n",
    "An additional notebook with further Data Exploration is also provided [here](APPENDIX_Bonus_Exploratory_Data.ipynb).\n",
    "\n",
    "\n",
    "## Setup environment\n",
    "### Install dependencies\n",
    "Before going further, please ensure that you have installed all required dependencies. This can easily be done through **[conda](https://docs.conda.io/en/latest/)**\n",
    "and the given `environment.yml` file  by running this command in a terminal (if you have conda, obviously):\n",
    "```\n",
    "conda env create -f environment.yml\n",
    "```\n",
    "\n",
    "If you do not have/want to use conda for any reason, you can still setup your environment by running some `pip install`\n",
    "commands. Please refer to the `environment.yml` file to see what are the dependencies you will need to install.  \n",
    "Basically, this project requires **Python 3.7** in addition to common datascience packages (such as \n",
    "**[numpy](https://www.numpy.org/)**, **[pandas](https://pandas.pydata.org/)**, \n",
    "**[sklearn](https://scikit-learn.org/stable/)**, **[matplotlib](https://matplotlib.org/)**, \n",
    "**[seaborn](https://seaborn.pydata.org/)** and so on).\n",
    "\n",
    "For modeling, this project is using models available in sklearn + **[xgboost](https://xgboost.readthedocs.io/en/latest/)**.  \n",
    "\n",
    "> NOTE: I made a NLP try on reviews, that is why there are:\n",
    "* **[gensim](https://radimrehurek.com/gensim/)**: used for topic modeling\n",
    "* **[wordcloud](https://pypi.org/project/wordcloud/)**: used to generate some tag clouds\n",
    "* **[spacy](https://spacy.io/)**: NLP package for easy lemmatization\n",
    "* **[pyLDAvis](https://pyldavis.readthedocs.io/en/latest/)**: great tool to visualize the topics with LDA (Latent Dirichlet Allocation)  \n",
    "\n",
    "> Feel free to skip them as for the moment the NLP part is not complete so not available in this repository.  \n",
    "My idea was to perform topic modeling on reviews per neighbourhood to see what were the relevant topics for each one but I have to handle language detection as some reviews are in french whereas others are in english (so need to load a different module in spacy for example). This would have led me far from the initial target so I decided to give up this part for the moment and focus on price prediction instead.\n",
    "\n",
    "### Get the data\n",
    "Run the cell below to download the data (be careful, depending on your network connection, this may take a while to run).  \n",
    "The script will:\n",
    "* create the `data` directory (be careful it will empty it if it already exists !)\n",
    "* collect 5 datasets from insideairbnb website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download started for file http://data.insideairbnb.com/france/ile-de-france/paris/2019-07-09/data/listings.csv.gz\n",
      "Download finished for file http://data.insideairbnb.com/france/ile-de-france/paris/2019-07-09/data/listings.csv.gz\n",
      "Download started for file http://data.insideairbnb.com/france/ile-de-france/paris/2019-07-09/visualisations/listings.csv\n",
      "Download finished for file http://data.insideairbnb.com/france/ile-de-france/paris/2019-07-09/visualisations/listings.csv\n",
      "Download started for file http://data.insideairbnb.com/france/ile-de-france/paris/2019-07-09/data/calendar.csv.gz\n",
      "Download finished for file http://data.insideairbnb.com/france/ile-de-france/paris/2019-07-09/data/calendar.csv.gz\n",
      "Download started for file http://data.insideairbnb.com/france/ile-de-france/paris/2019-07-09/data/reviews.csv.gz\n",
      "Download finished for file http://data.insideairbnb.com/france/ile-de-france/paris/2019-07-09/data/reviews.csv.gz\n",
      "Download started for file http://data.insideairbnb.com/france/ile-de-france/paris/2019-07-09/visualisations/neighbourhoods.csv\n",
      "Download finished for file http://data.insideairbnb.com/france/ile-de-france/paris/2019-07-09/visualisations/neighbourhoods.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../') \n",
    "\n",
    "from src.utils import datacollector\n",
    "\n",
    "datacollector.collect_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data are from **July 2019** (but if you want, you can download archives data from the website).  \n",
    "According to the insideairbnb website, the data contains those informations:  \n",
    "\n",
    "| File name          | File description                                                                |\n",
    "|--------------------|---------------------------------------------------------------------------------|\n",
    "| calendar.csv.gz    | Detailed Calendar Data for listings in Paris                                    |\n",
    "| reviews.csv.gz     | Detailed Review Data for listings in Paris                                      |\n",
    "| listings.csv.gz    | Detailed Listings data for Paris                                                |\n",
    "| listings.csv       | Summary information and metrics for listings in Paris (good for visualisations) |\n",
    "| neighbourhoods.csv | Neighbourhood list for geo filter. Sourced from city or open source GIS files   |\n",
    "\n",
    "---\n",
    "\n",
    "Now that we have both data and an environment up & running, let's start by exploring those files [here](1_Data_Understanding.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:udadsnd-p4] *",
   "language": "python",
   "name": "conda-env-udadsnd-p4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
